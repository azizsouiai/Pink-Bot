# Model Configuration
MODEL_NAME=openai/gpt-oss-120b
BACKEND=groq  # Options: huggingface, mistral_api, groq

# Device Configuration (for Hugging Face backend)
DEVICE=auto  # Options: auto, cpu, cuda, mps
TORCH_DTYPE=auto  # Options: auto, float16, bfloat16, float32
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false

# Groq API Configuration (required if BACKEND=groq)
GROQ_API_KEY=your_groq_api_key_here

# Mistral API Configuration (required if BACKEND=mistral_api)
MISTRAL_API_KEY=your_mistral_api_key_here

# Groq-specific Parameters
REASONING_EFFORT=medium  # Options: low, medium, high (for reasoning models)

# Generation Parameters
MAX_NEW_TOKENS=8192
TEMPERATURE=1.0
TOP_P=1.0
TOP_K=50
DO_SAMPLE=true

# System Prompt Configuration
SYSTEM_PROMPT_FILE=system_prompt.txt  # Path to system prompt file
